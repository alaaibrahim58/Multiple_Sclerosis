{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fa7d903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1321 files belonging to 2 classes.\n",
      "Found 331 files belonging to 2 classes.\n",
      "input_1\n",
      "block1_conv1\n",
      "block1_conv2\n",
      "block1_pool\n",
      "block2_conv1\n",
      "block2_conv2\n",
      "block2_pool\n",
      "block3_conv1\n",
      "block3_conv2\n",
      "block3_conv3\n",
      "block3_pool\n",
      "block4_conv1\n",
      "block4_conv2\n",
      "block4_conv3\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 14,715,201\n",
      "Trainable params: 7,079,937\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "42/42 [==============================] - 36s 491ms/step - loss: 0.8025 - accuracy: 0.6533\n",
      "\n",
      "Epoch 00001: accuracy improved from -inf to 0.65329, saving model to no_aug.h5\n",
      "Epoch 2/30\n",
      "42/42 [==============================] - 17s 392ms/step - loss: 0.4018 - accuracy: 0.8032\n",
      "\n",
      "Epoch 00002: accuracy improved from 0.65329 to 0.80318, saving model to no_aug.h5\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 17s 401ms/step - loss: 0.3086 - accuracy: 0.8653\n",
      "\n",
      "Epoch 00003: accuracy improved from 0.80318 to 0.86525, saving model to no_aug.h5\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 19s 427ms/step - loss: 0.2045 - accuracy: 0.9258\n",
      "\n",
      "Epoch 00004: accuracy improved from 0.86525 to 0.92581, saving model to no_aug.h5\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 20s 465ms/step - loss: 0.1618 - accuracy: 0.9478\n",
      "\n",
      "Epoch 00005: accuracy improved from 0.92581 to 0.94777, saving model to no_aug.h5\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 21s 495ms/step - loss: 0.1344 - accuracy: 0.9523\n",
      "\n",
      "Epoch 00006: accuracy improved from 0.94777 to 0.95231, saving model to no_aug.h5\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 23s 533ms/step - loss: 0.0922 - accuracy: 0.9682\n",
      "\n",
      "Epoch 00007: accuracy improved from 0.95231 to 0.96821, saving model to no_aug.h5\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 24s 546ms/step - loss: 0.0906 - accuracy: 0.9652\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.96821\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 25s 572ms/step - loss: 0.0419 - accuracy: 0.9864\n",
      "\n",
      "Epoch 00009: accuracy improved from 0.96821 to 0.98637, saving model to no_aug.h5\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 26s 610ms/step - loss: 0.0316 - accuracy: 0.9932\n",
      "\n",
      "Epoch 00010: accuracy improved from 0.98637 to 0.99319, saving model to no_aug.h5\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 29s 673ms/step - loss: 0.0191 - accuracy: 0.9947\n",
      "\n",
      "Epoch 00011: accuracy improved from 0.99319 to 0.99470, saving model to no_aug.h5\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 30s 713ms/step - loss: 0.0152 - accuracy: 0.9970\n",
      "\n",
      "Epoch 00012: accuracy improved from 0.99470 to 0.99697, saving model to no_aug.h5\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 32s 752ms/step - loss: 0.0051 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00013: accuracy improved from 0.99697 to 0.99849, saving model to no_aug.h5\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 36s 846ms/step - loss: 0.0213 - accuracy: 0.9947\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.99849\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 38s 888ms/step - loss: 0.0491 - accuracy: 0.9796\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.99849\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 39s 930ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00016: accuracy improved from 0.99849 to 1.00000, saving model to no_aug.h5\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 40s 944ms/step - loss: 0.0491 - accuracy: 0.9811\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 1.00000\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 34s 761ms/step - loss: 0.0127 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 1.00000\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 29s 634ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 1.00000\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 36s 841ms/step - loss: 7.5494e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 1.00000\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 34s 763ms/step - loss: 4.3188e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 1.00000\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 33s 737ms/step - loss: 2.6219e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 1.00000\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 27s 588ms/step - loss: 1.8540e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 1.00000\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 32s 741ms/step - loss: 1.3122e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 1.00000\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 34s 772ms/step - loss: 1.0067e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 1.00000\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 33s 741ms/step - loss: 6.9490e-05 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 1.00000\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 29s 656ms/step - loss: 5.2259e-05 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 1.00000\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 35s 811ms/step - loss: 4.0529e-05 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 1.00000\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 34s 771ms/step - loss: 3.3165e-05 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 1.00000\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 33s 749ms/step - loss: 3.4850e-05 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 1.00000\n",
      "11/11 [==============================] - 13s 986ms/step - loss: 0.1247 - accuracy: 0.9728\n",
      "Test accuracy: 0.973\n",
      "42/42 [==============================] - 27s 600ms/step - loss: 2.8923e-05 - accuracy: 1.0000\n",
      "Train accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#Using image_dataset_from_directory to read images\n",
    "train_dataset = image_dataset_from_directory( \n",
    "r\"C:\\Users\\muham\\Desktop\\Multiple_Sclerosis1\\train\",\n",
    "image_size=(224, 224),\n",
    "color_mode='rgb', \n",
    "label_mode='binary')\n",
    "\n",
    "test_dataset= image_dataset_from_directory(\n",
    "r\"C:\\Users\\muham\\Desktop\\Multiple_Sclerosis1\\test\",\n",
    "image_size=(224, 224),\n",
    "color_mode='rgb',\n",
    "label_mode='binary')\n",
    "#Define the model. \n",
    "#Here, we use pre-trained VGG16 layers and add GlobalAveragePooling and dense prediction layers.\n",
    "#Also, here we set the first few convolutional blocks as non-trainable and only train the last block.\n",
    "#This is just to speed up the training.  \n",
    "def get_model(input_shape = (224,224,3)):\n",
    "    \n",
    "    vgg = vgg16.VGG16(weights='imagenet', include_top=False, input_shape = input_shape )\n",
    "\n",
    "    for layer in vgg.layers[:-5]:    #Set block5 trainable, all others as non-trainable\n",
    "        print(layer.name)\n",
    "        layer.trainable = False #All others as non-trainable.\n",
    "\n",
    "    x = vgg.output\n",
    "    x = GlobalAveragePooling2D()(x) #Use GlobalAveragePooling and NOT flatten. \n",
    "    x = Dense(1, activation=\"sigmoid\")(x) \n",
    "\n",
    "    model = Model(vgg.input, x)\n",
    "    model.compile(loss = \"binary_crossentropy\", \n",
    "            optimizer = Adam(learning_rate=0.0001), metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "model = get_model(input_shape = (224,224,3))\n",
    "print(model.summary())\n",
    "\n",
    "checkup = ModelCheckpoint('no_aug.h5', monitor = 'accuracy', save_best_only = True, verbose = 1)\n",
    "history = model.fit(train_dataset, batch_size=16, epochs=30, verbose = 1, callbacks = [checkup])\n",
    "model.save(\"no_aug.h5\")\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")\n",
    "train_loss, train_acc = model.evaluate(train_dataset)\n",
    "print(f\"Train accuracy: {train_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eb7652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
